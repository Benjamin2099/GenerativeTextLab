{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===========================================\n",
    "# 1_data_exploration.ipynb\n",
    "# Analyse der FAQ-Daten und Wissensbasis im AskMeNow-Projekt\n",
    "# ===========================================\n",
    "\n",
    "# Zelle 1: Bibliotheken importieren\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Für Inline-Plots (falls nicht automatisch aktiviert)\n",
    "%matplotlib inline\n",
    "\n",
    "# Stelle sicher, dass NLTK-Tokendaten vorhanden sind (nur beim ersten Mal)\n",
    "nltk.download('punkt')\n",
    "\n",
    "# ===========================================\n",
    "# Zelle 2: Daten einlesen\n",
    "# ===========================================\n",
    "# Annahme: Die FAQ-Daten sind in einer CSV-Datei gespeichert, z.B. \"faq_data.csv\"\n",
    "# Diese Datei enthält mindestens die Spalten \"question\" und \"answer\".\n",
    "DATA_DIR = os.path.join(\"..\", \"data\", \"raw\")\n",
    "data_file = os.path.join(DATA_DIR, \"faq_data.csv\")\n",
    "\n",
    "df = pd.read_csv(data_file)\n",
    "print(\"Anzahl der FAQ-Einträge:\", len(df))\n",
    "display(df.head())\n",
    "\n",
    "# ===========================================\n",
    "# Zelle 3: Datenbereinigung (optional)\n",
    "# ===========================================\n",
    "def clean_text(text):\n",
    "    \"\"\"Entfernt HTML-Tags, überflüssige Leerzeichen und konvertiert den Text in Kleinbuchstaben.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip().lower()\n",
    "\n",
    "# Bereinige Fragen und Antworten\n",
    "df[\"clean_question\"] = df[\"question\"].apply(clean_text)\n",
    "df[\"clean_answer\"] = df[\"answer\"].apply(clean_text)\n",
    "\n",
    "print(\"\\nBereinigte Beispiele:\")\n",
    "display(df[[\"clean_question\", \"clean_answer\"]].head())\n",
    "\n",
    "# ===========================================\n",
    "# Zelle 4: Textlängen analysieren\n",
    "# ===========================================\n",
    "# Berechne die Länge der Fragen und Antworten (in Zeichen und in Tokens)\n",
    "df[\"question_length\"] = df[\"clean_question\"].apply(len)\n",
    "df[\"answer_length\"] = df[\"clean_answer\"].apply(len)\n",
    "df[\"question_token_count\"] = df[\"clean_question\"].apply(lambda x: len(nltk.word_tokenize(x)))\n",
    "df[\"answer_token_count\"] = df[\"clean_answer\"].apply(lambda x: len(nltk.word_tokenize(x)))\n",
    "\n",
    "print(\"\\nStatistiken zur Länge der Fragen (Zeichen):\")\n",
    "display(df[\"question_length\"].describe())\n",
    "\n",
    "print(\"\\nStatistiken zur Länge der Antworten (Zeichen):\")\n",
    "display(df[\"answer_length\"].describe())\n",
    "\n",
    "# ===========================================\n",
    "# Zelle 5: Visualisierung der Textlängen\n",
    "# ===========================================\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(df[\"question_token_count\"], bins=30, color=\"steelblue\", alpha=0.8)\n",
    "plt.xlabel(\"Anzahl Tokens (Fragen)\")\n",
    "plt.ylabel(\"Anzahl Einträge\")\n",
    "plt.title(\"Verteilung der Token-Anzahl in den Fragen\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(df[\"answer_token_count\"], bins=30, color=\"seagreen\", alpha=0.8)\n",
    "plt.xlabel(\"Anzahl Tokens (Antworten)\")\n",
    "plt.ylabel(\"Anzahl Einträge\")\n",
    "plt.title(\"Verteilung der Token-Anzahl in den Antworten\")\n",
    "plt.show()\n",
    "\n",
    "# ===========================================\n",
    "# Zelle 6: Häufigkeitsanalyse der Wörter\n",
    "# ===========================================\n",
    "# Tokenisierung der Fragen\n",
    "df[\"question_tokens\"] = df[\"clean_question\"].apply(nltk.word_tokenize)\n",
    "# Tokenisierung der Antworten\n",
    "df[\"answer_tokens\"] = df[\"clean_answer\"].apply(nltk.word_tokenize)\n",
    "\n",
    "# Erstelle einen Counter für alle Tokens in Fragen und Antworten\n",
    "all_question_tokens = [token for tokens in df[\"question_tokens\"] for token in tokens]\n",
    "all_answer_tokens = [token for tokens in df[\"answer_tokens\"] for token in tokens]\n",
    "\n",
    "question_counter = Counter(all_question_tokens)\n",
    "answer_counter = Counter(all_answer_tokens)\n",
    "\n",
    "print(\"\\nTop 10 häufigste Wörter in Fragen:\")\n",
    "print(question_counter.most_common(10))\n",
    "\n",
    "print(\"\\nTop 10 häufigste Wörter in Antworten:\")\n",
    "print(answer_counter.most_common(10))\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "q_tokens, q_freqs = zip(*question_counter.most_common(10))\n",
    "plt.bar(q_tokens, q_freqs, color=\"mediumpurple\")\n",
    "plt.xlabel(\"Wörter\")\n",
    "plt.ylabel(\"Häufigkeit\")\n",
    "plt.title(\"Top 10 Wörter in Fragen\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "a_tokens, a_freqs = zip(*answer_counter.most_common(10))\n",
    "plt.bar(a_tokens, a_freqs, color=\"coral\")\n",
    "plt.xlabel(\"Wörter\")\n",
    "plt.ylabel(\"Häufigkeit\")\n",
    "plt.title(\"Top 10 Wörter in Antworten\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# ===========================================\n",
    "# Zelle 7: Fazit & Nächste Schritte\n",
    "# ===========================================\n",
    "print(\"\"\"\n",
    "Fazit:\n",
    "- Die FAQ-Daten umfassen eine Vielzahl von Fragen und Antworten mit unterschiedlichen Längen und Token-Anzahlen.\n",
    "- Die Bereinigung und Tokenisierung liefern saubere, konsistente Texte.\n",
    "- Die Häufigkeitsanalyse zeigt, welche Wörter in den Fragen und Antworten dominieren.\n",
    "\n",
    "Nächste Schritte:\n",
    "- Weitere Datenbereinigung und -vorbereitung in notebooks/2_data_preprocessing.ipynb.\n",
    "- Aufteilung in Trainings-, Validierungs- und Test-Datensätze.\n",
    "- Entwicklung und Training eines Q&A-Modells (z. B. Seq2Seq oder Transformer-basierte Ansätze) in notebooks/3_training_demo.ipynb.\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
