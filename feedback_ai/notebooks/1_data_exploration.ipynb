{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===========================================\n",
    "# 1_data_exploration.ipynb\n",
    "# Analyse von generierten Texten & Feedback im Feedback AI-Projekt\n",
    "# ===========================================\n",
    "\n",
    "# Zelle 1: Bibliotheken importieren\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Für Inline-Plots in Jupyter Notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "# Stelle sicher, dass NLTK-Daten vorhanden sind\n",
    "nltk.download('punkt')\n",
    "\n",
    "# ===========================================\n",
    "# Zelle 2: Daten einlesen\n",
    "# ===========================================\n",
    "# Angenommen, die Feedback-Daten liegen in einer CSV-Datei im Ordner data/raw/\n",
    "# mit den Spalten \"generated_text\" und \"feedback\".\n",
    "RAW_DATA_DIR = os.path.join(\"..\", \"data\", \"raw\")\n",
    "data_file = os.path.join(RAW_DATA_DIR, \"feedback_raw.csv\")\n",
    "\n",
    "df = pd.read_csv(data_file)\n",
    "print(\"Anzahl der Einträge:\", len(df))\n",
    "display(df.head())\n",
    "\n",
    "# ===========================================\n",
    "# Zelle 3: Datenbereinigung\n",
    "# ===========================================\n",
    "def clean_text(text):\n",
    "    \"\"\"Entfernt HTML-Tags und überflüssige Leerzeichen, konvertiert den Text in Kleinbuchstaben.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip().lower()\n",
    "\n",
    "df[\"clean_text\"] = df[\"generated_text\"].apply(clean_text)\n",
    "print(\"\\nBeispiel bereinigter Texte:\")\n",
    "display(df[[\"generated_text\", \"clean_text\", \"feedback\"]].head())\n",
    "\n",
    "# ===========================================\n",
    "# Zelle 4: Tokenisierung & Wortstatistiken\n",
    "# ===========================================\n",
    "df[\"tokens\"] = df[\"clean_text\"].apply(nltk.word_tokenize)\n",
    "\n",
    "# Erstelle einen Counter für die Token\n",
    "all_tokens = [token for tokens in df[\"tokens\"] for token in tokens]\n",
    "token_counts = Counter(all_tokens)\n",
    "\n",
    "print(\"\\nTop 10 häufigste Wörter:\")\n",
    "print(token_counts.most_common(10))\n",
    "\n",
    "# Visualisiere die häufigsten Wörter\n",
    "tokens, freqs = zip(*token_counts.most_common(10))\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(tokens, freqs, color=\"cornflowerblue\")\n",
    "plt.xlabel(\"Wörter\")\n",
    "plt.ylabel(\"Häufigkeit\")\n",
    "plt.title(\"Top 10 häufigste Wörter in generierten Texten\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# ===========================================\n",
    "# Zelle 5: Feedback-Analyse\n",
    "# ===========================================\n",
    "# Analysiere die Verteilung des Feedbacks (z. B. \"thumbs_up\" vs. \"thumbs_down\")\n",
    "feedback_counts = df[\"feedback\"].value_counts()\n",
    "print(\"\\nFeedback-Verteilung:\")\n",
    "print(feedback_counts)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "feedback_counts.plot(kind=\"bar\", color=[\"seagreen\", \"tomato\"])\n",
    "plt.xlabel(\"Feedback\")\n",
    "plt.ylabel(\"Anzahl\")\n",
    "plt.title(\"Verteilung des Nutzerfeedbacks\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "# ===========================================\n",
    "# Zelle 6: Textlängen-Analyse\n",
    "# ===========================================\n",
    "df[\"text_length\"] = df[\"clean_text\"].apply(len)\n",
    "df[\"token_count\"] = df[\"tokens\"].apply(len)\n",
    "\n",
    "print(\"\\nStatistiken zur Textlänge (Zeichen):\")\n",
    "display(df[\"text_length\"].describe())\n",
    "print(\"\\nStatistiken zur Wortanzahl (Token):\")\n",
    "display(df[\"token_count\"].describe())\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(df[\"token_count\"], bins=30, color=\"mediumpurple\", alpha=0.8)\n",
    "plt.xlabel(\"Anzahl Tokens\")\n",
    "plt.ylabel(\"Anzahl Texte\")\n",
    "plt.title(\"Verteilung der Wortanzahl in generierten Texten\")\n",
    "plt.show()\n",
    "\n",
    "# ===========================================\n",
    "# Zelle 7: Fazit & Nächste Schritte\n",
    "# ===========================================\n",
    "print(\"\"\"\n",
    "Fazit:\n",
    "- Die Daten umfassen generierte Texte mit zugehörigem Nutzerfeedback.\n",
    "- Die Tokenisierung und Wortfrequenzanalyse zeigen die häufigsten Wörter und geben Aufschluss über den Sprachgebrauch.\n",
    "- Die Feedback-Verteilung zeigt, ob mehr positive oder negative Bewertungen vorliegen.\n",
    "\n",
    "Nächste Schritte:\n",
    "- Weitere Bereinigung und Vorverarbeitung der Daten (siehe Notebook 2_data_preprocessing.ipynb).\n",
    "- Analyse, ob bestimmte Textlängen oder Wortmuster mit positivem/negativem Feedback korrelieren.\n",
    "- Vorbereitung der Daten für das Training eines Feedback-gesteuerten Modells.\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
