{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =========================================================\n",
    "# 1_data_exploration.ipynb\n",
    "# =========================================================\n",
    "\n",
    "# Zelle 1: Bibliotheken importieren\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# Für Jupyter Notebook (inline Plots)\n",
    "# (Falls du in Jupyter-Lab oder .ipynb bist)\n",
    "# %matplotlib inline\n",
    "\n",
    "# Optional: Falls du Tokenisierung testen möchtest\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# ===========================================\n",
    "# Zelle 2: Daten laden\n",
    "# ===========================================\n",
    "# Angenommen, du hast in data/raw/ verschiedene Märchentexte als TXT oder CSV.\n",
    "# Wir zeigen hier ein Beispiel, wie du ggf. eine CSV mit \"text\" Spalte einlesen könntest.\n",
    "\n",
    "RAW_DATA_DIR = \"../data/raw\"\n",
    "sample_file = os.path.join(RAW_DATA_DIR, \"fairytales_sample.csv\")\n",
    "\n",
    "df = pd.read_csv(sample_file)\n",
    "print(\"Anzahl Datensätze:\", len(df))\n",
    "print(\"Erste Zeilen:\")\n",
    "display(df.head())\n",
    "\n",
    "# ===========================================\n",
    "# Zelle 3: Grober Überblick & Basis-Statistiken\n",
    "# ===========================================\n",
    "print(\"DataFrame Info:\")\n",
    "display(df.info())\n",
    "\n",
    "print(\"Anzahl fehlender Werte pro Spalte:\")\n",
    "display(df.isnull().sum())\n",
    "\n",
    "# Beispiel: Wir nehmen an, die \"text\"-Spalte enthält den Hauptinhalt der Märchen.\n",
    "df[\"length_text\"] = df[\"text\"].apply(lambda x: len(str(x)))\n",
    "print(\"\\nStatistiken zur Textlänge (Zeichen):\")\n",
    "display(df[\"length_text\"].describe())\n",
    "\n",
    "# ===========================================\n",
    "# Zelle 4: Erste Tokenisierung (Probe)\n",
    "# ===========================================\n",
    "# Wir können mal NLTK's word_tokenize testen,\n",
    "# um zu sehen, wie unsere Texte in Tokens zerfallen.\n",
    "\n",
    "def quick_tokenize(text):\n",
    "    tokens = nltk.word_tokenize(str(text))\n",
    "    return tokens\n",
    "\n",
    "df[\"sample_tokens\"] = df[\"text\"].apply(lambda x: quick_tokenize(x[:2000])[:30])\n",
    "# Hier beschränken wir uns auf die ersten 2000 Zeichen und zeigen 30 Tokens -> reiner Test\n",
    "\n",
    "print(\"\\nBeispiel-Tokenisierung (ersten 30 Tokens):\")\n",
    "display(df[[\"text\", \"sample_tokens\"]].head())\n",
    "\n",
    "# ===========================================\n",
    "# Zelle 5: Häufigste Wörter & Visualisierung\n",
    "# ===========================================\n",
    "from collections import Counter\n",
    "\n",
    "all_tokens = []\n",
    "for text in df[\"text\"].dropna():\n",
    "    # Als einfache Demo: tokenize das gesamte Textfeld\n",
    "    tokens = nltk.word_tokenize(str(text))\n",
    "    all_tokens.extend(tokens)\n",
    "\n",
    "word_freq = Counter(all_tokens)\n",
    "most_common_30 = word_freq.most_common(30)\n",
    "print(\"\\nHäufigste 30 Wörter/Tokens:\")\n",
    "for token, freq in most_common_30:\n",
    "    print(f\"{token}: {freq}\")\n",
    "\n",
    "# Kleines Balkendiagramm\n",
    "tokens_labels, tokens_counts = zip(*most_common_30)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(tokens_labels, tokens_counts)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Top 30 häufigste Tokens\")\n",
    "plt.show()\n",
    "\n",
    "# ===========================================\n",
    "# Zelle 6: Längenverteilung (Wörter)\n",
    "# ===========================================\n",
    "# Jetzt untersuchen wir, wie lang unsere Märchen typischerweise sind (in Wörtern).\n",
    "def count_words(text):\n",
    "    return len(nltk.word_tokenize(str(text)))\n",
    "\n",
    "df[\"word_count\"] = df[\"text\"].apply(count_words)\n",
    "print(\"\\nWortanzahl-Statistiken:\")\n",
    "display(df[\"word_count\"].describe())\n",
    "\n",
    "# Histogramm zu Wortlängen\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(df[\"word_count\"], bins=50)\n",
    "plt.xlabel(\"Wortanzahl pro Märchen/Text\")\n",
    "plt.ylabel(\"Anzahl Datensätze\")\n",
    "plt.title(\"Verteilung der Wortanzahl\")\n",
    "plt.show()\n",
    "\n",
    "# ===========================================\n",
    "# Zelle 7: Beispiele für sehr lange/kurze Texte\n",
    "# ===========================================\n",
    "long_texts = df.nlargest(3, \"word_count\")\n",
    "short_texts = df.nsmallest(3, \"word_count\")\n",
    "\n",
    "print(\"\\nBeispiele für sehr lange Märchen:\")\n",
    "display(long_texts[[\"text\", \"word_count\"]])\n",
    "\n",
    "print(\"\\nBeispiele für sehr kurze Märchen:\")\n",
    "display(short_texts[[\"text\", \"word_count\"]])\n",
    "\n",
    "# ===========================================\n",
    "# Zelle 8: Fazit & Ausblick\n",
    "# ===========================================\n",
    "# Basierend auf den Observations kannst du:\n",
    "#  - Entscheiden, ob du bestimmte Ausreißer (zu kurz/zu lang) entfernen willst\n",
    "#  - Ob du bestimmte Tokens oder Sonderzeichen bereinigen möchtest\n",
    "#  - Wie groß dein Vokabular ungefähr wird\n",
    "#  - Welche Sätze/Strukturen typisch sind, bevor du mit \"2_data_preprocessing.ipynb\" weitermachst.\n",
    "\n",
    "print(\"\\nFazit:\\n- Daten exploriert, erste Statistiken über Textlängen und häufige Tokens erhalten.\\n\"\n",
    "      \"- Nächster Schritt: Daten säubern, Tokenisierung verfeinern, Splits erstellen (Notebook 2).\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
