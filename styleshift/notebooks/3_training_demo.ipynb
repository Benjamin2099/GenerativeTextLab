{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===========================================\n",
    "# 3_training_demo.ipynb\n",
    "# Training & Evaluierung von Stiltransfer-Modellen\n",
    "# ===========================================\n",
    "\n",
    "# Zelle 1: Bibliotheken und Setup\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Gerät festlegen: GPU falls verfügbar, ansonsten CPU\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Verwende Gerät:\", DEVICE)\n",
    "\n",
    "# Definiere Pfade\n",
    "PROCESSED_DATA_DIR = \"../data/processed\"\n",
    "TRAIN_CSV = os.path.join(PROCESSED_DATA_DIR, \"train.csv\")\n",
    "VAL_CSV   = os.path.join(PROCESSED_DATA_DIR, \"val.csv\")\n",
    "VOCAB_JSON = os.path.join(PROCESSED_DATA_DIR, \"vocab.json\")\n",
    "\n",
    "# Zelle 2: Daten und Vokabular laden\n",
    "df_train = pd.read_csv(TRAIN_CSV)\n",
    "df_val   = pd.read_csv(VAL_CSV)\n",
    "\n",
    "with open(VOCAB_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "    word2id = json.load(f)\n",
    "id2word = {v: k for k, v in word2id.items()}\n",
    "\n",
    "vocab_size = len(word2id)\n",
    "pad_id = word2id.get(\"<PAD>\", 0)\n",
    "\n",
    "print(f\"Train Samples: {len(df_train)} | Val Samples: {len(df_val)}\")\n",
    "print(\"Vokabulargröße:\", vocab_size)\n",
    "# Schau dir ein paar Zeilen an\n",
    "display(df_train.head(3))\n",
    "\n",
    "# Zelle 3: Dataset-Klasse definieren\n",
    "class StyleShiftDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset für den Stiltransfer.\n",
    "    Erwartet in der CSV zwei Spalten:\n",
    "      - modern_ids: Token-IDs im modernen Stil (Input)\n",
    "      - shakespeare_ids: Token-IDs im Zielstil (Output)\n",
    "    \"\"\"\n",
    "    def __init__(self, df, input_col=\"modern_ids\", target_col=\"shakespeare_ids\"):\n",
    "        self.df = df.copy()\n",
    "        # Konvertiere Stringrepräsentationen in echte Listen, falls nötig\n",
    "        self.df[input_col] = self.df[input_col].apply(lambda x: eval(x) if isinstance(x, str) else x)\n",
    "        self.df[target_col] = self.df[target_col].apply(lambda x: eval(x) if isinstance(x, str) else x)\n",
    "        self.inputs = self.df[input_col].tolist()\n",
    "        self.targets = self.df[target_col].tolist()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        inp = torch.tensor(self.inputs[idx], dtype=torch.long)\n",
    "        tgt = torch.tensor(self.targets[idx], dtype=torch.long)\n",
    "        return inp, tgt\n",
    "\n",
    "def collate_fn(batch, pad_id=0):\n",
    "    inputs, targets = zip(*batch)\n",
    "    inputs_padded = pad_sequence(inputs, batch_first=True, padding_value=pad_id)\n",
    "    targets_padded = pad_sequence(targets, batch_first=True, padding_value=pad_id)\n",
    "    return inputs_padded, targets_padded\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = StyleShiftDataset(df_train, input_col=\"modern_ids\", target_col=\"shakespeare_ids\")\n",
    "val_dataset = StyleShiftDataset(df_val, input_col=\"modern_ids\", target_col=\"shakespeare_ids\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          collate_fn=lambda b: collate_fn(b, pad_id=pad_id))\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                        collate_fn=lambda b: collate_fn(b, pad_id=pad_id))\n",
    "\n",
    "print(\"Beispielhafter Batch:\")\n",
    "sample_inp, sample_tgt = next(iter(train_loader))\n",
    "print(\"Input-Shape:\", sample_inp.shape, \"Target-Shape:\", sample_tgt.shape)\n",
    "\n",
    "# Zelle 4: Modell definieren (Seq2Seq-LSTM für Stiltransfer)\n",
    "# Encoder: Liest den modernen Text\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers, pad_idx):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True)\n",
    "    \n",
    "    def forward(self, src):\n",
    "        # src: [Batch, src_len]\n",
    "        embedded = self.embedding(src)  # [Batch, src_len, embed_dim]\n",
    "        outputs, hidden = self.lstm(embedded)\n",
    "        return outputs, hidden\n",
    "\n",
    "# Decoder: Generiert den Text im Zielstil (z. B. Shakespeare)\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers, pad_idx):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "    \n",
    "    def forward(self, trg, hidden):\n",
    "        # trg: [Batch, trg_len]\n",
    "        embedded = self.embedding(trg)  # [Batch, trg_len, embed_dim]\n",
    "        outputs, hidden = self.lstm(embedded, hidden)\n",
    "        predictions = self.fc(outputs)  # [Batch, trg_len, vocab_size]\n",
    "        return predictions, hidden\n",
    "\n",
    "# Seq2Seq: Kombiniert Encoder und Decoder\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, pad_idx):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.pad_idx = pad_idx\n",
    "    \n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.size(0)\n",
    "        trg_len = trg.size(1)\n",
    "        vocab_size = self.decoder.fc.out_features\n",
    "        \n",
    "        outputs = torch.zeros(batch_size, trg_len, vocab_size).to(src.device)\n",
    "        \n",
    "        _, hidden = self.encoder(src)\n",
    "        \n",
    "        # Initialer Input für den Decoder: Das erste Token der Zielsequenz (<BOS>)\n",
    "        input_dec = trg[:, 0].unsqueeze(1)  # [Batch, 1]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden = self.decoder(input_dec, hidden)\n",
    "            outputs[:, t] = output.squeeze(1)\n",
    "            \n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(2)  # [Batch, 1]\n",
    "            input_dec = trg[:, t].unsqueeze(1) if teacher_force else top1\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "# Initialisierung des Modells\n",
    "EMBED_DIM = 128\n",
    "HIDDEN_DIM = 256\n",
    "NUM_LAYERS = 2\n",
    "\n",
    "encoder = Encoder(vocab_size, EMBED_DIM, HIDDEN_DIM, NUM_LAYERS, pad_id)\n",
    "decoder = Decoder(vocab_size, EMBED_DIM, HIDDEN_DIM, NUM_LAYERS, pad_id)\n",
    "model = Seq2Seq(encoder, decoder, pad_id).to(DEVICE)\n",
    "print(model)\n",
    "\n",
    "# Zelle 5: Trainings-Setup\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_id)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "EPOCHS = 5\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device, teacher_forcing_ratio):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for src, trg in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(src, trg, teacher_forcing_ratio=teacher_forcing_ratio)\n",
    "        output_dim = outputs.shape[-1]\n",
    "        outputs = outputs[:, 1:].reshape(-1, output_dim)\n",
    "        trg = trg[:, 1:].reshape(-1)\n",
    "        loss = criterion(outputs, trg)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, trg in loader:\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "            outputs = model(src, trg, teacher_forcing_ratio=0.0)\n",
    "            output_dim = outputs.shape[-1]\n",
    "            outputs = outputs[:, 1:].reshape(-1, output_dim)\n",
    "            trg = trg[:, 1:].reshape(-1)\n",
    "            loss = criterion(outputs, trg)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Zelle 6: Trainings- und Validierungsschleife\n",
    "best_val_loss = float(\"inf\")\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(f\"\\n=== Epoche {epoch}/{EPOCHS} ===\")\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion, DEVICE, teacher_forcing_ratio=0.5)\n",
    "    val_loss = evaluate(model, val_loader, criterion, DEVICE)\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        model_path = f\"styleshift_best_epoch{epoch}.pt\"\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(f\"** Neues bestes Modell gespeichert: {model_path}\")\n",
    "\n",
    "# Zelle 7: Inferenz-Demo – Stiltransfer\n",
    "def generate_styled_text(model, input_text, word2id, id2word, max_length=50):\n",
    "    \"\"\"\n",
    "    Generiert eine stilisierte Version des input_text.\n",
    "    Hier gehen wir davon aus, dass input_text im modernen Stil vorliegt.\n",
    "    Wir wandeln den Text in Token-IDs um, fügen ein <BOS> hinzu und generieren dann den Zielstil.\n",
    "    \"\"\"\n",
    "    # Tokenisierung (einfach per split – in der Praxis die gleiche Methode wie in der Vorverarbeitung verwenden)\n",
    "    tokens = input_text.lower().split()\n",
    "    input_ids = [word2id.get(token, word2id.get(\"<UNK>\", 1)) for token in tokens]\n",
    "    \n",
    "    # Füge <BOS> hinzu (angenommen, <BOS> ist das erste Token im Vokabular für den Zielstil)\n",
    "    bos_id = word2id.get(\"<BOS>\", 2)\n",
    "    input_dec = torch.tensor([[bos_id]], dtype=torch.long).to(DEVICE)\n",
    "    \n",
    "    # Konvertiere den modern-stiligen Input in einen Tensor\n",
    "    src = torch.tensor([input_ids], dtype=torch.long).to(DEVICE)\n",
    "    \n",
    "    # Encoder: Artikel verarbeiten\n",
    "    _, hidden = encoder(src)\n",
    "    \n",
    "    generated_ids = [bos_id]\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            output, hidden = decoder(input_dec, hidden)\n",
    "            next_id = output.argmax(dim=2).item()\n",
    "            if next_id == word2id.get(\"<EOS>\", 3):\n",
    "                break\n",
    "            generated_ids.append(next_id)\n",
    "            input_dec = torch.tensor([[next_id]], dtype=torch.long).to(DEVICE)\n",
    "    \n",
    "    return \" \".join([id2word.get(i, \"<UNK>\") for i in generated_ids])\n",
    "\n",
    "# Beispiel für die Inferenz\n",
    "example_input = \"ich freue mich auf den sommer\"\n",
    "styled_output = generate_styled_text(model, example_input, word2id, id2word, max_length=20)\n",
    "print(\"\\nBeispiel für Stiltransfer:\")\n",
    "print(\"Modern:\", example_input)\n",
    "print(\"Stilisierte Version:\", styled_output)\n",
    "\n",
    "# Zelle 8: Fazit & Ausblick\n",
    "print(\"\"\"\n",
    "Fazit:\n",
    "- Das Modell wurde erfolgreich trainiert und zeigt einen sinkenden Validierungs-Loss.\n",
    "- Erste Inferenz-Demos demonstrieren den Stiltransfer von modern zu einem anderen Stil.\n",
    "Nächste Schritte:\n",
    "- Mehr Daten und Epochen für bessere Ergebnisse.\n",
    "- Erweiterung des Modells um Transformer-Ansätze (z.B. GPT-2/T5) für noch realistischere Stiltransfers.\n",
    "- Feinabstimmung der Hyperparameter und Erprobung von Sampling-Methoden.\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
